{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nvImageCodecs with cv-cuda (Linux only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io.image import read_file, decode_jpeg\n",
    "os.chdir(\"/mnt/c/Users/smatysik/projects/nvImageCodecsWSL/build/bin/python\")\n",
    "resources_dir = \"../../../resources\"\n",
    "import nvimgcodecs\n",
    "import nvcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"{}/base/tabby_tiger_cat.jpg\".format(resources_dir) # \"cat_q95_444.jpg\"\n",
    "inputImage = nvimgcodecs.imread(file_name)\n",
    "print(\"size:{}x{}\".format(inputImage.width, inputImage.height))\n",
    "#Planar (CHW) -> Interleave (NHWC)\n",
    "inputImage = cp.asarray(inputImage)\n",
    "inputImage = cp.moveaxis(inputImage, (0, 1, 2), (2, 0, 1))\n",
    "inputImage = cp.asfortranarray(inputImage)\n",
    "inputImage = cp.ascontiguousarray(inputImage)\n",
    "inputImage = cp.reshape(\n",
    "    inputImage, (1, inputImage.shape[0], inputImage.shape[1], inputImage.shape[2]))\n",
    "\n",
    "nvcvInputTensor = nvcv.as_tensor(inputImage, \"NHWC\") \n",
    "nvcvResizeTensor = nvcvInputTensor.resize((1, 320, 320, 3), nvcv.Interp.CUBIC)\n",
    "\n",
    "cuda_array = nvcvResizeTensor.cuda().__cuda_array_interface__ \n",
    "class cuda_array_wrapper:\n",
    "    __cuda_array_interface__ = {'shape': tuple(cuda_array['shape']), 'strides': tuple(\n",
    "        cuda_array['strides']), 'typestr': 'B', 'data': cuda_array['data'], 'version': 2}\n",
    "a = cuda_array_wrapper()\n",
    "\n",
    "cp_img = cp.asarray(a)\n",
    "cp_img = cp.reshape(cp_img, (cp_img.shape[1], cp_img.shape[2], cp_img.shape[3]))\n",
    "image = cp.asnumpy(cp_img)\n",
    "plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import numpy as np\n",
    "file_name = \"{}/base/tabby_tiger_cat.jpg\".format(resources_dir)\n",
    "labelsfile = \"{}/imagenet-classes.txt\".format(resources_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read with torch (which uses nvJpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file(file_name)\n",
    "inputImageTmp = decode_jpeg(data, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name = \"{}/base/cat.j2k\".format(resources_dir)\n",
    "#file_name = \"{}/base/4k_lossless.jp2\".format(resources_dir)\n",
    "inputImage = nvimgcodecs.imread(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageWidth = inputImage.width\n",
    "imageHeight = inputImage.height\n",
    "\n",
    "#Planar (CHW) -> Interleave (NHWC)\n",
    "inputImage = cp.asarray(inputImage)\n",
    "inputImage = cp.moveaxis(inputImage, (0, 1, 2), (2, 0, 1))\n",
    "inputImage = cp.asfortranarray(inputImage)\n",
    "inputImage = cp.ascontiguousarray(inputImage)\n",
    "\n",
    "image = cp.asnumpy(inputImage)\n",
    "plt.imshow(image)\n",
    "\n",
    "inputImage = cp.reshape(\n",
    "    inputImage, (1, inputImage.shape[0], inputImage.shape[1], inputImage.shape[2]))\n",
    "\n",
    "# A torch tensor/ or nvImageCodecs Image can be wrapped into a CVCUDA Object using the \"as_tensor\"\n",
    "# function in the specified layout. The datatype and dimensions are derived\n",
    "# directly from the torch tensor.\n",
    "nvcvInputTensor = nvcv.as_tensor(inputImage, \"NHWC\") \n",
    "\n",
    "\"\"\"\n",
    "Preprocessing includes the following sequence of operations.\n",
    "Resize -> DataType Convert(U8->F32) -> Normalize(Apply mean and std deviation)\n",
    "-> Interleaved to Planar\n",
    "\"\"\"\n",
    "\n",
    "# Model settings\n",
    "layerHeight = 224\n",
    "layerWidth = 224\n",
    "batchSize = 1\n",
    "\n",
    "# Resize\n",
    "# Resize to the input network dimensions\n",
    "nvcvResizeTensor = nvcvInputTensor.resize(\n",
    "    (batchSize, layerHeight, layerWidth, 3), nvcv.Interp.CUBIC)\n",
    "    \n",
    "# Convert to the data type and range of values needed by the input layer\n",
    "# i.e uint8->float. A Scale is applied to normalize the values in the range 0-1\n",
    "nvcvConvertTensor = nvcvResizeTensor.convertto(np.float32, scale=1 / 255)\n",
    "\n",
    "\"\"\"\n",
    "The input to the network needs to be normalized based on the mean and\n",
    "std deviation value to standardize the input data.\n",
    "\"\"\"\n",
    "\n",
    "# Create a torch tensor to store the mean and standard deviation values for R,G,B\n",
    "scale = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "scaleTensor = torch.Tensor(scale)\n",
    "stdTensor = torch.Tensor(std)\n",
    "\n",
    "# Reshape the the number of channels. The R,G,B values scale and offset will be\n",
    "# applied to every color plane respectively across the batch\n",
    "scaleTensor = torch.reshape(scaleTensor, (1, 1, 1, 3)).cuda()\n",
    "stdTensor = torch.reshape(stdTensor, (1, 1, 1, 3)).cuda()\n",
    "\n",
    "# Wrap the torch tensor in a CVCUDA Tensor\n",
    "nvcvScaleTensor = nvcv.as_tensor(scaleTensor, \"NHWC\")\n",
    "nvcvBaseTensor = nvcv.as_tensor(stdTensor, \"NHWC\")\n",
    "\n",
    "# Apply the normalize operator and indicate the scale values are std deviation\n",
    "# i.e scale = 1/stddev\n",
    "nvcvNormTensor = nvcvConvertTensor.normalize(\n",
    "    nvcvBaseTensor, nvcvScaleTensor, nvcv.NormalizeFlags.SCALE_IS_STDDEV\n",
    ")\n",
    "                                                         \n",
    "# The final stage in the preprocess pipeline includes converting the RGB buffer\n",
    "# into a planar buffer\n",
    "nvcvPreprocessedTensor = nvcvNormTensor.reformat(\"NCHW\")   \n",
    "\n",
    "# Inference uses pytorch to run a resnet50 model on the preprocessed input and outputs\n",
    "# the classification scores for 1000 classes\n",
    "# Load Resnet model pretrained on Imagenet\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.to(\"cuda\")\n",
    "resnet50.eval()\n",
    "\n",
    "# Run inference on the preprocessed input\n",
    "torchPreprocessedTensor = torch.as_tensor(nvcvPreprocessedTensor.cuda(), device=\"cuda\")\n",
    "inferOutput = resnet50(torchPreprocessedTensor)\n",
    "\n",
    "\"\"\"\n",
    "Postprocessing function normalizes the classification score from the network and sorts\n",
    "the scores to get the TopN classification scores.\n",
    "\"\"\"\n",
    "# top results to print out\n",
    "topN = 5\n",
    "\n",
    "# Read and parse the classes\n",
    "with open(labelsfile, \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Apply softmax to Normalize scores between 0-1\n",
    "scores = torch.nn.functional.softmax(inferOutput, dim=1)[0]\n",
    "\n",
    "# Sort output scores in descending order\n",
    "_, indices = torch.sort(inferOutput, descending=True)\n",
    "\n",
    "# Display Top N Results\n",
    "for idx in indices[0][:topN]:\n",
    "    print(\"Class : \", classes[idx], \" Score : \", scores[idx].item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code below does not work as expected - how to make reformat properly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data = read_file(\"tabby_tiger_cat.jpg\")\n",
    "data = read_file(\"cat_q95_444.jpg\")\n",
    "inputImage = decode_jpeg(data, device=\"cuda\")\n",
    "print(\"torch: \", inputImage.__cuda_array_interface__)\n",
    "\n",
    "inputImage = cp.asarray(inputImage)\n",
    "#print(\"torch->cp: \", inputImage.__cuda_array_interface__)\n",
    "inputImage = cp.moveaxis(inputImage, (0, 1, 2), (2, 0, 1))\n",
    "inputImage = cp.asfortranarray(inputImage)\n",
    "print(\"cp CHW (column-major): \", inputImage.__cuda_array_interface__)\n",
    "inputImage = cp.asfortranarray(inputImage)\n",
    "print(\"cp CHW (column-major): \", inputImage.__cuda_array_interface__)\n",
    "inputImage = cp.ascontiguousarray(inputImage)\n",
    "\n",
    "# orignally it was \"CHW\" but reformat assumes for CHW column-major so interleave anyway and need to be packed pitch for dim2 ==1\n",
    "nvcvInputTensor = nvcv.as_tensor(inputImage, \"HWC\") \n",
    "nvcvInputTensor = nvcvInputTensor.reformat(\"NCHW\")\n",
    "print(\"nvcv NCHW: \", nvcvInputTensor.cuda().__cuda_array_interface__)\n",
    "\n",
    "nvcvInterleavedTensor =  nvcvInputTensor.reformat(\"NHWC\")\n",
    "print(\"nvcv NHWC: \", nvcvInterleavedTensor.cuda().__cuda_array_interface__)\n",
    "\n",
    "nvcvResizeTensor = nvcvInterleavedTensor.resize((1, 320, 240, 3), nvcv.Interp.CUBIC)\n",
    "\n",
    "cuda_array = nvcvResizeTensor.cuda().__cuda_array_interface__ \n",
    "class cuda_array_wrapper:\n",
    "    __cuda_array_interface__ = {'shape': tuple(cuda_array['shape']), 'strides': tuple(\n",
    "        cuda_array['strides']), 'typestr': 'B', 'data': cuda_array['data'], 'version': 2}\n",
    "a = cuda_array_wrapper()\n",
    "print(\"nvcv (tuple) NHWC: \", a.__cuda_array_interface__)\n",
    "\n",
    "cp_img = cp.asarray(a)\n",
    "print(\"cupy NHWC: \", cp_img.__cuda_array_interface__)\n",
    "cp_img = cp.reshape(\n",
    "    cp_img, (cp_img.shape[1], cp_img.shape[2], cp_img.shape[3]))\n",
    "#print(\"cupy reshaped NHWC: \", cp_img.__cuda_array_interface__)\n",
    "#cp_img = cp.asfortranarray(cp_img)\n",
    "#cp_img = cp.ascontiguousarray(cp_img)\n",
    "image = cp.asnumpy(cp_img)\n",
    "plt.imshow(image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
